---
title : "MLP"
excerpt : "Machine Learning"
use_math : true
categories :
  - 머신러닝
tags :
  - MLP
---
**포스텍 최승진 교수님 강의와 강의자료를 참고했습니다.**  

---
>머신러닝이란?

training을 통해 문제를 해결하는 방법 중 하나이다. 가장 중요한 세가지로 **data**, **model**, **training algorithm** 이 있다.
* data = vector = list of numbers
* model = linear models, deep neural network  
* training algorithm = gradient descent

---
>Supervised Learning vs Unsupervised Learning  

labeled data = (x,y) -> Supervised Learnning  
ex) Classification, Regression  
unlabeled data = (x) -> Unsupervised Learning  
ex) GAN

---
> Linear Classification

![](/assets/images/Linear Classification.png){: .align-center}

사전에 Linear Model을 사용하는 이유는 수학적으로 쉽기 때문이다. 아주 완벽한 Theory가 존재하기 때문에 먼저 Linear하게 풀려고 사람들이 먼저 노력하고 이후에 성능을 높이고자 non-linear한 모델로 간다. neural network 또한 non-linear 하지만 linear의 특성을 가지고 있다.  

해당 Linear Function은 다음과 같다.  
$$f\left( x \right) ={ w }^{ T }x+b$$
hyperplane(직선의 방정식)은 $${ w }^{ T }x+b=0$$ 정의된다.

---
>퍼셉트론(Perceptron) : A single layer neural network  

머신러닝 초창기 모델로서 layer가 확장되어 MLP(Multilayer Perceptron)이 되었다. MLP는 fully connected network라고도 불리운다.  

0보다 크면 1, 작으면 -1로 분류하는데 neural network와 logistic regression에서는 (1,0)을 사용하며 큰 차이는 없다.  


퍼셉트론의 가장 큰 특징은 **iterative algorithm** 으로 한번에 값을 찾아내는 것이 아닌 반복적으로 업데이트를 하는 알고리즘이다. 또한, **mistake-driven** 의 특성을 지니고 있는데 iterative하게 업데이트를 하면서 잘못 예측한 경우(-1을 1로 or 1을 -1로)에만 parameter 값을 업데이트 해준다는 특성이다.

![](/assets/images/Linearly Separable.png){: .align-center}

마지막으로 퍼셉트론이 MLP로 바뀌게 된 결정적인 이유는 **"Linearly Separable"** 라는 약점이 있었기 때문이다. Linearly Separable이란 위의 사진을 보면 linear hyperplane 즉, 선형적인 직선으로 두 클래스가 나뉘어져야 된다는 것이다.

---
